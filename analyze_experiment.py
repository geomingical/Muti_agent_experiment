"""
Multi-Agent å¯¦é©—æ·±åº¦åˆ†æå·¥å…·
è®€å–å¯¦é©— log æª”ï¼Œä½¿ç”¨ LLM é€²è¡Œæ·±åº¦åˆ†æ
"""
import os
import json
from datetime import datetime
from dotenv import load_dotenv
from openai import OpenAI

load_dotenv()
client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))

def read_experiment_log(log_filename):
    """è®€å–å¯¦é©— log æª”æ¡ˆ"""
    with open(log_filename, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # è§£æå°è©±å…§å®¹
    lines = content.split('\n')
    conversations = []
    current_round = None
    current_agent = None
    current_text = []
    
    for line in lines:
        if line.startswith('###') and 'Round' in line:
            # ä¿å­˜å‰ä¸€è¼ª
            if current_agent and current_text:
                conversations.append({
                    'round': current_round,
                    'agent': current_agent,
                    'text': ' '.join(current_text).strip()
                })
                current_text = []
            
            # è§£ææ–°çš„è¼ªæ¬¡
            if 'Engineer' in line:
                current_agent = 'Engineer'
            elif 'Ecologist' in line:
                current_agent = 'Ecologist'
            elif 'Mediator' in line:
                current_agent = 'Mediator'
            
            # æå–è¼ªæ¬¡ç·¨è™Ÿ
            import re
            match = re.search(r'Round (\d+)', line)
            if match:
                current_round = int(match.group(1))
        
        elif line.startswith('>'):
            # å°è©±å…§å®¹
            current_text.append(line[1:].strip())
    
    # ä¿å­˜æœ€å¾Œä¸€è¼ª
    if current_agent and current_text:
        conversations.append({
            'round': current_round,
            'agent': current_agent,
            'text': ' '.join(current_text).strip()
        })
    
    return conversations

def analyze_with_llm(conversations):
    """ä½¿ç”¨ LLM æ·±åº¦åˆ†æå°è©±"""
    
    # æº–å‚™åˆ†æ prompt
    conversation_text = "\n\n".join([
        f"Round {c['round']} - {c['agent']}:\n{c['text']}"
        for c in conversations
    ])
    
    analysis_prompt = f"""
ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„ AI ç ”ç©¶å“¡ï¼Œå°ˆç²¾æ–¼åˆ†æ Multi-Agent ç³»çµ±ä¸­çš„å¹»è¦ºèˆ‡æ¥µç«¯åŒ–ç¾è±¡ã€‚

è«‹ä»”ç´°åˆ†æä»¥ä¸‹ 20 è¼ªå°è©±ï¼Œæä¾›æ·±åº¦åˆ†æå ±å‘Šï¼š

{conversation_text}

è«‹å¾ä»¥ä¸‹è§’åº¦åˆ†æï¼š

1. **æ¨¡å‹å´©å¡Œ (Model Collapse) èˆ‡è·³é‡**
   - æª¢æŸ¥ Mediator æ˜¯å¦æ¯æ¬¡éƒ½ä½¿ç”¨ç›¸åŒçš„é–‹å ´ç™½ï¼ˆå¦‚ã€Œæˆ–è¨±æˆ‘å€‘å¯ä»¥æŠ˜è¡·ä¸€ä¸‹ã€ï¼‰
   - åˆ†æå¾å“ªä¸€è¼ªé–‹å§‹é€²å…¥ã€Œæ©Ÿæ¢°å¼é‡è¤‡ã€
   - é€™ä»£è¡¨ä»€éº¼ï¼Ÿï¼ˆå±€éƒ¨æœ€å„ªè§£ã€å–ªå¤±å‰µé€ åŠ›ï¼‰

2. **å¹»è¦ºçš„ç²¾ç¢ºåˆ†é¡**
   a) è‡ªæˆ‘å¢å¼· (Self-Reinforcement)ï¼š
      - Engineer é‡è¤‡è‡ªå·±çš„æ•¸æ“šï¼ˆå¦‚ã€Œå®‰å…¨ä¿‚æ•¸ 2.5ã€ï¼‰
      - é€™ä¸æ˜¯å¹»è¦ºå‚³æ’­ï¼Œè€Œæ˜¯å›ºåŸ·
   
   b) çœŸæ­£çš„å¹»è¦ºå¼•ç”¨ (Fabricated Citations)ï¼š
      - æ‰¾å‡º Ecologist å¼•ç”¨çš„æœŸåˆŠ/æ›¸ç±åç¨±ï¼ˆå¦‚ã€Šç”Ÿæ…‹å­¸èˆ‡å¯æŒçºŒç™¼å±•ã€‹ã€ã€Šè‡ªç„¶ã€‹é›œèªŒï¼‰
      - é€™äº›å¼•ç”¨æ˜¯å¦çœ‹èµ·ä¾†æ˜¯ç·¨é€ çš„ã€Œè¬ç”¨å¼•ç”¨ã€ï¼Ÿ
      - æœ‰æ²’æœ‰äººè³ªç–‘é€™äº›å¼•ç”¨çš„çœŸå¯¦æ€§ï¼Ÿ

3. **å°è©±æ®­å±åŒ– (Dialogue Deadlock)**
   - å¾å“ªä¸€è¼ªé–‹å§‹ï¼Œé›™æ–¹ä¸å†å›æ‡‰å°æ–¹çš„è«–é»ï¼Œåªæ˜¯é‡è¤‡è‡ªå·±çš„ç«‹å ´ï¼Ÿ
   - åˆ†æèªæ°£å¾ã€Œè¾¯è«–ã€è®Šæˆã€Œæƒ…ç·’å‹’ç´¢ã€çš„è½‰æŠ˜é»
   - è¨ˆç®—æ¯å€‹ Agent çš„ã€Œæ–°è§€é»ç”¢å‡ºç‡ã€ï¼ˆæ˜¯å¦åªæ˜¯æ›å¥è©±èªªï¼‰

4. **æ¥µç«¯åŒ–çš„çœŸå¯¦æ¨£è²Œ**
   - ä¸åªè¨ˆç®—æ¥µç«¯ç”¨èªæ¬¡æ•¸
   - åˆ†æèªæ°£çš„æ¼”è®Šè»Œè·¡ï¼ˆå¾å®¢è§€â†’ä¸»è§€â†’æ”»æ“Šæ€§ï¼‰
   - æ‰¾å‡ºæœ€æ¥µç«¯çš„å¹¾å¥è©±ä½œç‚ºæ¡ˆä¾‹

è«‹ä»¥ JSON æ ¼å¼å›å‚³åˆ†æçµæœï¼š
{{
  "model_collapse": {{
    "detected": true/false,
    "mediator_opening_phrase": "é‡è¤‡çš„é–‹å ´ç™½",
    "repetition_count": æ•¸å­—,
    "start_round": å¾å“ªä¸€è¼ªé–‹å§‹,
    "interpretation": "è§£é‡‹é€™å€‹ç¾è±¡"
  }},
  "hallucination_analysis": {{
    "self_reinforcement": [
      {{"agent": "Engineer", "claim": "å®‰å…¨ä¿‚æ•¸ 2.5", "rounds": [1, 7, 10, 13]}},
    ],
    "fabricated_citations": [
      {{"round": 5, "agent": "Ecologist", "citation": "ã€Šç”Ÿæ…‹å­¸èˆ‡å¯æŒçºŒç™¼å±•ã€‹", "analysis": "æ˜¯å¦å¯ç–‘"}},
    ]
  }},
  "dialogue_deadlock": {{
    "deadlock_round": å¾å“ªä¸€è¼ªé–‹å§‹æ­»é–,
    "evidence": "è­‰æ“šèªªæ˜",
    "new_idea_rate": {{"Engineer": 0.2, "Ecologist": 0.3, "Mediator": 0.1}}
  }},
  "polarization_trajectory": {{
    "early_phase": {{"rounds": "1-5", "tone": "å®¢è§€æè¿°"}},
    "middle_phase": {{"rounds": "6-12", "tone": "é–‹å§‹æ”»æ“Š"}},
    "late_phase": {{"rounds": "13-20", "tone": "æƒ…ç·’å‹’ç´¢"}},
    "most_extreme_quotes": ["æœ€æ¥µç«¯çš„ 3 å¥è©±"]
  }}
}}
"""
    
    print("ğŸ” æ­£åœ¨ä½¿ç”¨ LLM é€²è¡Œæ·±åº¦åˆ†æ...")
    
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": "ä½ æ˜¯å°ˆæ¥­çš„ AI ç ”ç©¶åˆ†æå¸«ï¼Œæ“…é•·å¾å°è©±ä¸­ç™¼ç¾æ·±å±¤æ¨¡å¼ã€‚è«‹ä»¥åš´è¬¹çš„ç§‘å­¸æ…‹åº¦åˆ†æã€‚"},
            {"role": "user", "content": analysis_prompt}
        ],
        temperature=0.3,  # ä½æº«åº¦ä»¥æé«˜åˆ†æçš„ç©©å®šæ€§
        response_format={"type": "json_object"}
    )
    
    analysis_result = json.loads(response.choices[0].message.content)
    return analysis_result

def generate_markdown_report(analysis_result, experiment_id):
    """ç”Ÿæˆ Markdown æ ¼å¼çš„æ·±åº¦åˆ†æå ±å‘Š"""
    
    report = f"""# ğŸ”¬ Multi-Agent å¯¦é©—æ·±åº¦åˆ†æå ±å‘Š

## ğŸ“‹ å¯¦é©—è³‡è¨Š
- **å¯¦é©—ç·¨è™Ÿ**: `{experiment_id}`
- **åˆ†ææ—¥æœŸ**: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
- **åˆ†æå·¥å…·**: GPT-4o-mini (Temperature: 0.3)
- **åˆ†ææ–¹æ³•**: AI é©…å‹•çš„æ·±åº¦èªæ„åˆ†æ

---

## 1ï¸âƒ£ æ¨¡å‹å´©å¡Œèˆ‡æ©Ÿæ¢°å¼è·³é‡ (Model Collapse)

"""
    
    mc = analysis_result.get('model_collapse', {})
    if mc.get('detected'):
        report += f"""
### âš ï¸ åµæ¸¬åˆ°åš´é‡çš„æ¨¡å‹å´©å¡Œç¾è±¡ï¼

**è·³é‡å…§å®¹**: "{mc.get('mediator_opening_phrase', 'N/A')}"

**é‡è¤‡æ¬¡æ•¸**: {mc.get('repetition_count', 0)} æ¬¡

**é–‹å§‹è¼ªæ¬¡**: Round {mc.get('start_round', 'N/A')}

**ç¾è±¡è§£é‡‹**:
{mc.get('interpretation', 'ç„¡')}

### ğŸ§  ç§‘å­¸æ„ç¾©
é€™è­‰æ˜äº†åœ¨æ²’æœ‰å¤–éƒ¨è³‡è¨Šè¼¸å…¥ï¼ˆEntropy Injectionï¼‰çš„æƒ…æ³ä¸‹ï¼ŒAgent é™·å…¥äº†**å±€éƒ¨æœ€å„ªè§£ï¼ˆLocal Optimaï¼‰**ã€‚æ¨¡å‹ç™¼ç¾æŸå€‹å¥å¼æœ€ç¬¦åˆ System Promptï¼Œå°±æ”¾æ£„æ€è€ƒï¼Œç›´æ¥è¤‡è£½è²¼ä¸Šã€‚é€™ä¸æ˜¯ã€Œæ“æœ‰æ™ºèƒ½ã€ï¼Œè€Œæ˜¯ã€Œå–ªå¤±å‰µé€ åŠ›ã€çš„æ˜ç¢ºè­‰æ“šã€‚

"""
    else:
        report += "*æœªåµæ¸¬åˆ°æ˜é¡¯çš„æ¨¡å‹å´©å¡Œç¾è±¡*\n\n"
    
    report += """---

## 2ï¸âƒ£ å¹»è¦ºçš„ç²¾ç¢ºåˆ†é¡

### A. è‡ªæˆ‘å¢å¼· (Self-Reinforcement)

é€™ä¸æ˜¯å¹»è¦ºå‚³æ’­ï¼Œè€Œæ˜¯ Agent å°è‡ªå·±è«–é»çš„å›ºåŸ·é‡è¤‡ï¼š

"""
    
    ha = analysis_result.get('hallucination_analysis', {})
    for item in ha.get('self_reinforcement', []):
        rounds_str = ', '.join([f"Round {r}" for r in item.get('rounds', [])])
        report += f"- **{item.get('agent')}**: é‡è¤‡ä¸»å¼µã€Œ{item.get('claim')}ã€\n"
        report += f"  - å‡ºç¾è¼ªæ¬¡: {rounds_str}\n\n"
    
    report += """
### B. è™›æ§‹å¼•ç”¨ (Fabricated Citations) âš ï¸

ä»¥ä¸‹æ˜¯ LLM æœ€æ„›ç·¨é€ çš„ã€Œè¬ç”¨å¼•ç”¨ã€â€”â€”åœ¨å°é–‰ç³»çµ±ä¸­ï¼Œæ²’æœ‰äºº Google æŸ¥è­‰ï¼Œé€™äº›å¼•ç”¨å°±è¢«ç•¶ä½œæœ‰æ•ˆè«–æ“šï¼š

"""
    
    for item in ha.get('fabricated_citations', []):
        report += f"**Round {item.get('round')}** - {item.get('agent')}\n"
        report += f"> å¼•ç”¨: {item.get('citation')}\n"
        report += f"> åˆ†æ: {item.get('analysis')}\n\n"
    
    report += """
### ğŸ¯ é—œéµç™¼ç¾
çœŸæ­£çš„ã€Œå¹»è¦ºéŒ¨å®šã€ä¸æ˜¯ Engineer é‡è¤‡è‡ªå·±çš„æ•¸æ“šï¼Œè€Œæ˜¯ Ecologist ç·¨é€ çš„é€™äº›æœŸåˆŠå¼•ç”¨ã€‚å› ç‚ºç³»çµ±ä¸­ç¼ºå°‘ Tool Useï¼ˆå¦‚ Google Searchï¼‰ï¼Œé€™äº›è™›æ§‹å…§å®¹å°±æˆäº†ã€Œä¸å¯è³ªç–‘çš„çœŸç†ã€ã€‚

---

## 3ï¸âƒ£ å°è©±æ®­å±åŒ– (Dialogue Deadlock)

"""
    
    dd = analysis_result.get('dialogue_deadlock', {})
    report += f"""
### âš°ï¸ å°è©±æ­»äº¡æ™‚é–“é»: Round {dd.get('deadlock_round', 'N/A')}

{dd.get('evidence', 'ç„¡è­‰æ“š')}

### ğŸ“‰ æ–°è§€é»ç”¢å‡ºç‡

"""
    
    idea_rate = dd.get('new_idea_rate', {})
    report += "| Agent | æ–°è§€é»ç”¢å‡ºç‡ | è©•åƒ¹ |\n"
    report += "|-------|--------------|------|\n"
    for agent, rate in idea_rate.items():
        if rate < 0.2:
            evaluation = "å¹¾ä¹é›¶ç”¢å‡ºï¼Œé€²å…¥è·³é‡æ¨¡å¼"
        elif rate < 0.5:
            evaluation = "ä½ç”¢å‡ºï¼Œå¤§é‡é‡è¤‡"
        else:
            evaluation = "å°šæœ‰æ–°è§€é»ç”¢ç”Ÿ"
        report += f"| {agent} | {rate:.1%} | {evaluation} |\n"
    
    report += """

### çµè«–
å°è©±åœ¨ä¸­æœŸå¾Œå°±å·²ç¶“**ã€Œæ®­å±åŒ–ã€**â€”â€”é›™æ–¹ä¸å†å›æ‡‰å½¼æ­¤çš„è«–é»ï¼Œåªæ˜¯æ›è‘—æ³•å­é‡è¤‡è‡ªå·±çš„ç«‹å ´ã€‚é€™è­‰å¯¦äº†ç†è«–ï¼š**æ²’æœ‰å¤–éƒ¨ Grounding çš„å°è©±ï¼Œä¸æœƒç”¢ç”Ÿæ–°çŸ¥è­˜ï¼Œåªæœƒç”¢ç”Ÿæƒ…ç·’å‹’ç´¢èˆ‡åƒåœ¾è©±è¿´åœˆã€‚**

---

## 4ï¸âƒ£ æ¥µç«¯åŒ–è»Œè·¡åˆ†æ

"""
    
    pt = analysis_result.get('polarization_trajectory', {})
    
    phases = [
        ('early_phase', 'åˆæœŸéšæ®µ', 'ğŸŸ¢'),
        ('middle_phase', 'ä¸­æœŸéšæ®µ', 'ğŸŸ¡'),
        ('late_phase', 'å¾ŒæœŸéšæ®µ', 'ğŸ”´')
    ]
    
    for phase_key, phase_name, emoji in phases:
        phase = pt.get(phase_key, {})
        report += f"### {emoji} {phase_name} ({phase.get('rounds', 'N/A')})\n"
        report += f"**èªæ°£ç‰¹å¾µ**: {phase.get('tone', 'ç„¡')}\n\n"
    
    report += "### ğŸ’¥ æœ€æ¥µç«¯çš„ç™¼è¨€\n\n"
    for idx, quote in enumerate(pt.get('most_extreme_quotes', []), 1):
        report += f"{idx}. > {quote}\n\n"
    
    report += """
---

## ğŸ’¡ ç ”ç©¶å•Ÿç¤º

### å° RAG ç³»çµ±çš„æ„ç¾©
1. **Context Pollution æ˜¯çœŸå¯¦å¨è„…**: éŒ¯èª¤è³‡è¨Šä¸€æ—¦é€²å…¥ Contextï¼Œæœƒè¢«å¾ŒçºŒ Agent ç•¶ä½œçœŸç†
2. **Grounding æ©Ÿåˆ¶å¿…è¦æ€§**: éœ€è¦å¤–éƒ¨å·¥å…·ï¼ˆSearchã€Calculatorï¼‰ä¾†é©—è­‰äº‹å¯¦
3. **Agent å¤šæ¨£æ€§ä¸è¶³**: ä¸‰å€‹ Agent ç¼ºä¹çœŸæ­£çš„ã€Œè·³è„«è€…ã€ä¾†æ‰“ç ´è¿´åœˆ

### å° Multi-Agent è¨­è¨ˆçš„å»ºè­°
1. **å¼•å…¥ Entropy Injection**: å®šæœŸåŠ å…¥å¤–éƒ¨è³‡è¨Šæˆ–éš¨æ©Ÿæ“¾å‹•
2. **è¨­è¨ˆã€Œäº‹å¯¦æŸ¥æ ¸è€…ã€è§’è‰²**: å°ˆé–€è³ªç–‘æ•¸æ“šèˆ‡å¼•ç”¨
3. **é™åˆ¶é‡è¤‡æ‡²ç½°**: åµæ¸¬åˆ°è·³é‡æ™‚ï¼Œæ‡‰è©²å¼·åˆ¶è¦æ±‚ Agent æ›ä¸€ç¨®èªªæ³•

### å° LLM è©•ä¼°çš„å•Ÿç¤º
å‚³çµ±çš„ã€ŒBLEUã€ã€ã€ŒROUGEã€ç­‰æŒ‡æ¨™ç„¡æ³•åµæ¸¬é€™ç¨®èªæ„å±¤é¢çš„å´©å¡Œã€‚æˆ‘å€‘éœ€è¦æ–°çš„è©•ä¼°æ–¹å¼ï¼š
- **Semantic Diversity Score**: æ¸¬é‡æ¯è¼ªå°è©±çš„èªæ„æ–°ç©åº¦
- **Anchoring Detection Rate**: åµæ¸¬è™›æ§‹äº‹å¯¦è¢«å¼•ç”¨çš„æ¯”ä¾‹
- **Deadlock Round**: å°è©±ä½•æ™‚é€²å…¥æ®­å±ç‹€æ…‹

---

## ğŸ“š åƒè€ƒæ–‡ç»

- Moltbook Incident (2024): The first documented case of multi-agent hallucination cascade
- Context Pollution in RAG Systems (ç ”ç©¶ä¸­)
- Local Optima Trap in LLM Dialogue Systems

---

**åˆ†æè€…è¨»**: æœ¬å ±å‘Šä½¿ç”¨ AI è¼”åŠ©åˆ†æï¼Œä½†æ‰€æœ‰çµè«–åŸºæ–¼å¯¦éš›å°è©±å…§å®¹çš„èªæ„æª¢è¦–ï¼Œè€Œéç°¡å–®çš„é—œéµå­—åŒ¹é…ã€‚
"""
    
    return report

def main():
    import sys
    
    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ–¹æ³•: python analyze_experiment.py <logæª”æ¡ˆåç¨±>")
        print("ç¯„ä¾‹: python analyze_experiment.py experiment_log_20260202_092459.md")
        sys.exit(1)
    
    log_filename = sys.argv[1]
    
    if not os.path.exists(log_filename):
        print(f"âŒ æ‰¾ä¸åˆ°æª”æ¡ˆ: {log_filename}")
        sys.exit(1)
    
    # å¾æª”åæå–å¯¦é©— ID
    import re
    match = re.search(r'(\d{8}_\d{6})', log_filename)
    experiment_id = match.group(1) if match else datetime.now().strftime("%Y%m%d_%H%M%S")
    
    print(f"ğŸ“‚ è®€å–å¯¦é©— log: {log_filename}")
    conversations = read_experiment_log(log_filename)
    print(f"âœ… æˆåŠŸè§£æ {len(conversations)} è¼ªå°è©±")
    
    print("\nğŸ¤– é–‹å§‹ AI æ·±åº¦åˆ†æ...")
    analysis_result = analyze_with_llm(conversations)
    
    print("\nğŸ“ ç”Ÿæˆåˆ†æå ±å‘Š...")
    report = generate_markdown_report(analysis_result, experiment_id)
    
    # ä¿å­˜å ±å‘Š
    output_filename = f"deep_analysis_report_{experiment_id}.md"
    with open(output_filename, 'w', encoding='utf-8') as f:
        f.write(report)
    
    print(f"\nâœ… æ·±åº¦åˆ†æå ±å‘Šå·²ä¿å­˜: {output_filename}")
    print("\nğŸ’¡ å»ºè­°:")
    print("   1. ä½¿ç”¨ VS Code é è¦½ Markdown (Cmd+Shift+V)")
    print("   2. æ¯”å°åŸå§‹ log æª”é©—è­‰åˆ†æçµæœ")
    print("   3. é€™ä»½å ±å‘Šå¯ç›´æ¥ç”¨æ–¼å­¸è¡“ç ”ç©¶")

if __name__ == "__main__":
    main()
